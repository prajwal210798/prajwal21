<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Hum@n_G@ze</title>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Raleway:300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,500,700,900" rel="stylesheet">
    <link rel="stylesheet" href="css/bootstrap.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/CLOUSRE_REPORT.css">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="responsive.css">
</head>

<body>
    <div class="wrapper">
        <header class="header">
            <div class="container">
                <div class="row">
                    <div class="col-md-2">
                        <div class="logo">
                            <h2><a href="https://www.drdo.gov.in/labs-and-establishments/centre-artificial-intelligence-robotics-cair">CAIR LAB</a></h2>
                        </div>
                    </div>
                    <div class="col-md-10">
                        <div class="menu">
                            <ul>
                                <li class="active"><a href="../index.html">Home</a></li>
                                <!--<li><a href="#">lifestyle</a></li>
                                <li><a href="#">Food</a></li>
                                <li><a href="#">Nature</a></li>
                                <li><a href="#">photography</a></li> -->
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <section class="bg-text-area">
            <div class="container">
                <div class="row">
                    <div class="col-md-12">
                        <div class="bg-text">
                            <h3>PERCEPTION INFORMED BY
                                NAVIGATION FOR SEARCH AND
                                RESCUE</h3>
                            
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <br>
        <br>
        <div class="container">
        <p align="center" style="margin-bottom: 0cm; line-height: 115%"><font face="Times New Roman, serif"><font size="4" style="font-size: 14pt"><span lang="en-US"><u><b>
            INTRODUCTION</b></u></span></font></font></p>
            <p lang="en-US" align="justify" style="margin-bottom: 0cm; line-height: 115%">
            <br>
            
            </p>
            <p align="justify" style="margin-bottom: 0cm; line-height: 115%"><font face="Times New Roman, serif"><font size="3" style="font-size: 12pt"><span lang="en-US"><b>Introduction:	</b></span></font></font></p>
            <?xml version="1.0" encoding="UTF-8"?>
            <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><!--This file was converted to xhtml by LibreOffice - see http://cgit.freedesktop.org/libreoffice/core/tree/filter/source/xslt for the code.--><head profile="http://dublincore.org/documents/dcmi-terms/"><meta http-equiv="Content-Type" content="application/xhtml+xml; charset=utf-8"/><title xml:lang="en-US">- no title specified</title><meta name="DCTERMS.title" content="" xml:lang="en-US"/><meta name="DCTERMS.language" content="en-US" scheme="DCTERMS.RFC4646"/><meta name="DCTERMS.source" content="http://xml.openoffice.org/odf2xhtml"/><meta name="DCTERMS.issued" content="2020-06-27T11:28:16.003485789" scheme="DCTERMS.W3CDTF"/><meta name="DCTERMS.modified" content="2020-07-03T06:59:43.193134084" scheme="DCTERMS.W3CDTF"/><meta name="DCTERMS.provenance" content="" xml:lang="en-US"/><meta name="DCTERMS.subject" content="," xml:lang="en-US"/><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/" hreflang="en"/><link rel="schema.DCTERMS" href="http://purl.org/dc/terms/" hreflang="en"/><link rel="schema.DCTYPE" href="http://purl.org/dc/dcmitype/" hreflang="en"/><link rel="schema.DCAM" href="http://purl.org/dc/dcam/" hreflang="en"/><style type="text/css">
                @page {  }
                table { border-collapse:collapse; border-spacing:0; empty-cells:show }
                td, th { vertical-align:top; font-size:12pt;}
                h1, h2, h3, h4, h5, h6 { clear:both;}
                ol, ul { margin:0; padding:0;}
                li { list-style: none; margin:0; padding:0;}
                /* "li span.odfLiEnd" - IE 7 issue*/
                li span. { clear: both; line-height:0; width:0; height:0; margin:0; padding:0; }
                span.footnodeNumber { padding-right:1em; }
                span.annotation_style_by_filter { font-size:95%; font-family:Arial; background-color:#fff000;  margin:0; border:0; padding:0;  }
                span.heading_numbering { margin-right: 0.8rem; }* { margin:0;}
                .fr1 { font-size:12pt; margin-left:0cm; margin-right:0cm; font-family:Liberation Serif; vertical-align:middle; margin-top:0cm; margin-bottom:0cm; }
                .P1 { font-size:12pt; font-family:Liberation Serif; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; }
                .P10_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; letter-spacing:normal; font-style:normal; font-weight:normal; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P10 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; letter-spacing:normal; font-style:normal; font-weight:normal; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P10_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; letter-spacing:normal; font-style:normal; font-weight:normal; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P11_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; letter-spacing:normal; font-style:normal; font-weight:normal; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P11 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; letter-spacing:normal; font-style:normal; font-weight:normal; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P11_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; letter-spacing:normal; font-style:normal; font-weight:normal; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P12_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P12 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P12_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P13_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P13 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P13_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P14_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P14 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P14_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P15_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P15 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P15_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P16_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P16 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P16_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#1c1c1c; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P17_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#0066b3; font-style:normal; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P17 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#0066b3; font-style:normal; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P17_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:0cm; color:#0066b3; font-style:normal; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P18_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:1.27cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P18 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:1.27cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P18_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:1.27cm; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P19_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-top:0cm; line-height:115%; text-align:justify ! important; text-indent:1.27cm; color:#1c1c1c; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P19 { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; line-height:115%; text-align:justify ! important; text-indent:1.27cm; color:#1c1c1c; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P19_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-left:0cm; margin-right:0cm; margin-bottom:0cm; line-height:115%; text-align:justify ! important; text-indent:1.27cm; color:#1c1c1c; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P2 { font-size:12pt; font-family:Times new roman; writing-mode:page; color:#1c1c1c; font-style:normal; background-color:transparent; }
                .P20_borderStart { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-top:0cm; line-height:115%; text-align:justify ! important; color:#1c1c1c; font-style:normal; background-color:transparent; padding-bottom:0cm;  border-bottom-style:none; }
                .P20 { font-size:12pt; font-family:Times new roman; writing-mode:page; line-height:115%; text-align:justify ! important; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm; padding-bottom:0cm;  border-top-style:none; border-bottom-style:none; }
                .P20_borderEnd { font-size:12pt; font-family:Times new roman; writing-mode:page; margin-bottom:0cm; line-height:115%; text-align:justify ! important; color:#1c1c1c; font-style:normal; background-color:transparent; padding-top:0cm;  border-top-style:none;}
                .P3 { font-size:12pt; font-family:Times new roman; writing-mode:page; color:#1c1c1c; font-style:normal; background-color:transparent; }
                .P4 { font-size:12pt; font-family:Times new roman; writing-mode:page; color:#1c1c1c; font-style:normal; background-color:transparent; }
                .P5 { font-size:12pt; font-family:Times new roman; writing-mode:page; color:#1c1c1c; background-color:transparent; }
                .P6 { font-size:12pt; font-family:Times new roman; writing-mode:page; color:#1c1c1c; background-color:transparent; }
                .P7 { font-size:12pt; font-family:Times new roman; writing-mode:page; color:#1c1c1c; background-color:#fff200; }
                .P8 { font-size:12pt; font-family:Times new roman; writing-mode:page; color:#1c1c1c; background-color:transparent; }
                .P9 { font-size:12pt; font-family:Times new roman; writing-mode:page; color:#00aaad; font-style:normal; background-color:transparent; }
                .Emphasis { font-style:italic; }
                .T2 { font-weight:normal; }
                .T21 { letter-spacing:normal; font-weight:normal; }
                .T22 { letter-spacing:normal; font-weight:normal; }
                .T23 { letter-spacing:normal; font-weight:normal; }
                .T24 { letter-spacing:normal; font-weight:normal; }
                .T25 { letter-spacing:normal; font-weight:normal; }
                .T3 { font-weight:normal; }
                .T34 { color:#1c1c1c; font-family:Times new roman; font-size:12pt; letter-spacing:normal; font-style:normal; font-weight:normal; background-color:transparent; }
                .T35 { color:#1c1c1c; font-family:Times new roman; font-size:12pt; letter-spacing:normal; font-style:normal; font-weight:normal; background-color:transparent; }
                .T37 { font-weight:normal; }
                .T53 { font-size:12pt; }
                .T54 { font-size:12pt; }
                .T55 { font-size:12pt; }
                .T56 { font-size:12pt; }
                .T57 { font-size:12pt; }
                .T58 { font-size:12pt; font-weight:normal; }
                .T59 { font-size:12pt; font-weight:normal; background-color:#ed1c24; }
                .T60 { font-size:12pt; background-color:#ed1c24; }
                .T61 { font-size:12pt; }
                .T69 { color:#1c1c1c; font-family:Times new roman; font-size:12pt; font-style:normal; background-color:transparent; }
                .T7 { font-weight:normal; background-color:#fff200; }
                .T70 { color:#1c1c1c; font-family:Times new roman; font-size:12pt; font-style:normal; background-color:transparent; }
                .T8 { font-weight:normal; background-color:#fff200; }
                /* ODF styles with no properties representable as CSS */
                .T1 .T62 .T63 .T64  { }
                </style></head><body dir="ltr" style="max-width:21.001cm;margin-top:2cm; margin-bottom:2cm; margin-left:2cm; margin-right:2cm; "><p class="P9">This work presents a time dependent metric for object’s confidence  which closely resembles the  behavior inherit by human for detecting an object ,and its inclusion in the pre implemented detection and   tracking algorithm like SORT[],DEEPSORT[].In contrast to other existed tracking algorithm where temporal information is extracted from sequence of frames to enhance tracking this work uses infromation gathered from tracker and generate the the temporal confidence of an object without affecting the fps of existed tracking algorithms.</p><p class="P2"> </p><p class="P2"> </p><p class="P3"><span class="T1">Object  detection and </span>tracking plays an important role in computer vision field, and numerous tracking approaches have been proposed with demonstrated <span class="T1">success.</span><span class="T2">Most of the conventional detection and tracking algorithms for moving objects involves pre-processing, background subtraction (along with dynamic background modelling), detection foreground object(s) (particularly the moving objects), post-processing, and </span><span class="T3">then </span><span class="T2">tracking </span><span class="T8">[</span><span class="T7">Bahadir Karasulu and Serdar Korukoglu,.: Springer, 2013, ch. 2, pp. 7-30.</span><span class="T8">].</span></p><p class="P20_borderStart"><span class="T62">An input image is most often pre-processed for normalizing contrast and brightness effects [4]. On the other hand, a color space transformation (e.g. RGB to LAB color space) may help to get better results while dealing with color images. </span></p><p class="P12"><span class="T62">The </span><span class="T63">preprocessing</span><span class="T62"> step is followed by the Feature Extraction. The input image contains much extra information that is not necessary for classification. Therefore, prior to image classification, the target image is simplified by extracting the important information contained in the image and leaving out the rest.  However, the image can be simplified by running an edge detector on the image. It is still easily possible to discern the circular shape of the buttons in these edge images. Therefore, it can be concluded that edge detection retains the essential information while throwing away non-essential information. However, designing these features is crucial to the performance of the algorithm in a traditional computer vision approaches. </span></p><p class="P18"><span class="T62">A much better performance can be achieved finding much more reliable features than the simple edge detection. In the example of shirt and coat buttons, a good feature detector will not only capture the circular shape of the buttons but also gather information about how buttons are different from other circular objects like car tires. Some well-known features used in computer vision are Haar-like features (introduced by Viola and Jones) [5], Histogram of Oriented Gradients (HOG) [6,7], Scale-Invariant Feature Transform (SIFT) [8,9], Speeded Up Robust Feature (SURF) [10] etc.</span></p><p class="P14">Now, after converting an image to a corresponding feature vector, classification algorithm takes this feature vector as input and outputs a class label. However, these classification algorithms are required to be trained before it can actually determine the classes of the objects. The algorithms need to be trained by showing thousands of examples of images from different target and known classes.</p><p class="P12_borderEnd"><span class="T62">The classification algorithms/classifiers are majorly clustered in - Linear classifier, Quadratic classifier, Bayesian classifier, Neural Network, Kernel estimation and k-nearest neighbor, Decision Trees, Support Vector Machines, Maximum Entropy Classifier etc. Among these algorithms, the mostly cultured classifier is the Neural Network based classifier. After classification, post-processing is used to refine the bounding box, eliminate duplicate detections, and rescore the box based on other objects in the scene. However, these complex pipelines are slow and hard to optimize because each individual component must be trained separately. To resolve this limitation, some new algorithms like YOLO [11] has been proposed which trains the classifier to find multiple objects in a single frame in one go. The algorithm has proved its potentiality in terms of speed and accuracy.</span></p><p class="P3"><span class="T37"> </span><span class="T62">Nevertheless, in spite of these long sustained researches in this field, there still exists a missing single temporal based  metric which can estimate the confidence of the tracked object. </span></p><p class="P4"/><p class="P4"> </p><p class="P4"> </p><p class="P12"><span class="T62">As per the best knowledge of authors </span><span class="T64">existed</span><span class="T62"> tracking algorithm uses the temporal information to  enhance the tracking process and  not the confidence parameter .</span></p><p class="P1"><span class="T69">Currently The tracking process is achieved by using a combination of spatial and temporal information about the moving object. </span><span class="T70">Most of the time </span><span class="T34">A motion model </span><span class="T35">is </span><span class="T34"> used  </span><span class="T35">along with other tricks </span><span class="T34">that captures the dynamic behavior of an object. I</span><span class="Emphasis"><span class="T34">t predicts the potential position of objects in the future frames, hence, reducing the search space. </span></span><span class="T34">YOLO with kalman Filter has been a popular choice . </span><span class="Emphasis"><span class="T34">However, the motion model alone can fail in scenarios where motion is caused by things that are not in a video or abrupt direction and speed change.</span></span></p><p class="P10"> <span> Multiple object tracking is more challenging than single object tracking where a algorithm needs to distinguish between  object of same class and also  needs to track all object in a scene. SORT[single online real time tracking ] algorithm uses the motion model of an object with other tricks such as IOU , Hungarian matching algorithm .</span></p><p class="P10_borderEnd"/><p class="P8"><span class="T55">The discussed object detection and tracking  algorithms </span><span class="T56">and other existed  algorithms  </span><span class="T57">often</span><span class="T56"> </span><span class="T55">uses motion model which is a kind of temporal based method to enhance the tracking but fails to incorporate this with the confidence parameter. </span><span class="T53">This is because; the current algorithms simply implement a passive object detection running on the live camera images [12] and predict the confidence of the detected object based on a single frame  only .Contrary to this Humans has the tendency to strongly correlate its current  knowledge of the object at time t with the  knowledge gathered from previous time steps to increase or decrease its confidence about the  identified object. </span></p><p class="P8"><span class="T53">        Therefore;we can make more informed decision about the  detected object  by inclusion of  two analogous property inherited by the humans in existing object tracking algorithms.</span></p><p class="P15_borderStart"/><p class="P16_borderEnd"><span class="T60">First </span><span class="T53">is</span><span class="T58"> time dependent iconic memory of a Human . </span><span class="T55">A approach towards the formulating the time dependency of iconic memory of human  has been done in a paper:</span></p><p class="P7">Graziano M, Sigman M (2008) The dynamics of sensory buffers: Geometric, spatial, and experience-dependent shaping of iconic memory. Journal of Vision 8: 9,1–13.</p><p class="P5">In this paper they have conducted an experiment where observers had to identify the position of  specific subset of the characters at an interval (Inter Stimulus Interval, ISI)</p><p class="P5">This paper has reported the time dependent confidence of the iconic memory as :</p><!--Next 'div' was a 'text:p'.--><div class="P8"><!--Next '
                        span' is a draw:frame.
                    --><span id="a_1"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                   <mrow>
                     <mi>p</mi>
                     <mrow>
                      <mi>'</mi>
                      <mo stretchy="false">=</mo>
                      <mi>a</mi>
                     </mrow>
                     <mi>∗</mi>
                     <mi>e</mi>
                     <mi>∧</mi>
                     <mrow>
                      <mrow>
                       <mo fence="true" stretchy="true">(</mo>
                       <mrow>
                        <mrow>
                         <mrow>
                          <mi>−</mi>
                          <mi>t</mi>
                         </mrow>
                         <mo stretchy="false">/</mo>
                         <mi>τ</mi>
                        </mrow>
                       </mrow>
                       <mo fence="true" stretchy="true">)</mo>
                      </mrow>
                      <mo stretchy="false">+</mo>
                      <mi>b</mi>
                     </mrow>
                    </mrow>
                  </math> </span><!--Next 'div' added for floating.--><div style="position:relative; left:0cm;"><span class="T61"> ---------------------(1)</span></div></div><div style="clear:both; line-height:0; width:0; height:0; margin:0; padding:0;"> </div><p class="P6">p’=probability confidence of identifing the spatial position  of the letter</p><p class="P6">a,b, tou= free parameters</p><p class="P19">t=ISI time</p><p class="P6">tau : C (the time constant) indicates the temporal constant which characterizes the exponential decay in performance, i.e., the duration of iconic memory.}</p><!--Next 'div' was a 'text:p'.--><div class="P16"><span class="T53">This formula can be interperated as follows , to identify the position of the letter after shorter dutration of time a human can use both its iconic memory(</span><!--Next '
                        span' is a draw:frame.
                    --><span id="Object1"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                   <mrow>
                     <mi>a</mi>
                     <mi>∗</mi>
                     <mi>e</mi>
                     <mi>∧</mi>
                     <mrow>
                      <mo fence="true" stretchy="true">(</mo>
                      <mrow>
                       <mrow>
                        <mrow>
                         <mi>−</mi>
                         <mi>t</mi>
                        </mrow>
                        <mo stretchy="false">/</mo>
                        <mi>τ</mi>
                       </mrow>
                      </mrow>
                      <mo fence="true" stretchy="true">)</mo>
                     </mrow>
                    </mrow>
                  </math> </span><!--Next 'div' added for floating.--><div style="position:relative; left:0cm;"><span class="T53">term) as well as long term memory(constant memory) but after some time (2*tau, or 3*tau) the probability confidence of iconic memory decreases in very large extent and now human can only depend on  its long term memory to identify the position.</span></div></div><div style="clear:both; line-height:0; width:0; height:0; margin:0; padding:0;"> </div><p class="P8"><span class="T61">This formula shows the exponential  time dependency of the confidence level in identifying the positon of the characters and can be extended further in evaluating the time dependent confidence of detecting the object in computer vision, Our proposed algorithm has also the  exponental dependency on the time dependent factors.</span></p><p class="P6"> </p><p class="P16_borderStart"><span class="T59">Second </span><span class="T58">, Humans lingers its gaze in an object until it is detected properly [13].</span><span class="T53">The gaze tries to obtain a temporal continuity between the consecutive </span><span class="T54">time </span><span class="T53">frames while the object is in motion. Otherwise, the continuity is obtained by moving our gaze around the object to collect more features about it. Temporal continuity while detection help humans to correlate its previous knowledge about the object and thus combine it with new received information and increase its confidence of detection  of a object correctly. </span></p><p class="P11"><span> </span></p><p class="P11">This work thus gathers inspiration from the above mentioned behavior which occurs naturally across humans, birds and most animals. Some strategies have also been proposed in the same direction [14], but they yet required to be improved further for real-time implementation. </p><p class="P13"><span class="T21">        </span></p><p class="P17_borderEnd"><span class="T21">In this wo</span><span class="T22">r</span><span class="T21">k </span><span class="T24">to </span><span class="T21"> Incorporate </span><span class="T23">above two discussed temporal behavior (lingering affect and  exponential time dependency ) to make informed decision about the detected object confidence  we use algorithm which incorporate the time dependency and for  </span><span class="T22">lingering affect </span><span class="T24"> </span><span class="T22">we </span><span class="T23">use information  </span><span class="T25">obtained from tracker implemented in SORT and then  use all the previous </span><span class="T22"> sequence of frames </span><span class="T23">to derive object’</span><span class="T25">s</span><span class="T23"> confidence.</span><span class="T22">  </span></p></body></html>
        
        </div>
        
        <br>
        <br>
        <br>
        <div class="container">
            <p class="noindent" >In this work, object detection has been implemented using the well-known
                You-Only-Look-Once (YOLO) algorithm. Like most other deep-neural-network based
                detection algorithms, the YOLO algorithm detects objects in an image frame. This
                excludes the possibility to relate the temporal information of an object with its
                detection confidence. On the other hand, a conventional tracking algorithm cannot
                detect an object, but is able to relate the present position of an arbitrary object with
                its previous position. Therefore; fusion of YOLO with a tracking algorithm, e.g.
                Kalman Filter based tracking, is made in this work to improve the detection
                confidence of an object.
                <!--l. 286--><p class="indent" >   Most of the existing object detection and tracking algorithms that are present
                today for ready to use does not associate the temporal information of the object with
                its detection congidence. In this work, the temporal imformation of the object has
                been associated to improve the confidence of the object. In other words, machine
                ability to identify an object has been enhanced through countinous gazing to the
                object and thus building up the confidence to indentify the object particularly in low
                light condition .
                <!--l. 295--><p class="indent" >   The formula that is proposed here uses the confidences of an detected object and
                assign it to a tracker for the object. Then the confidences of the successive
                detections have been associated with the tracker confidence through the propose 
                formula.
                <br>
                <br>
                <b>The formula will be made public after publication of confrence paper</b>
                <br>
                <br>
                <!--video insert-->
                
                Here are the links of generated video files :
                <h4><a href="https://youtu.be/dsmI0yg0fR4">Bottle_output</a></h4>
                You can see here that initially object is not identified as its  confidence through proposed algorithm will be too low, once its accumulate the confidence from its previos frame its correctly identify the object as bootle with good confidence.
                <!--done-->






                </p>
                <!--l. 320--><p class="indent" >   Experiments that are carried on the various lighting conditions have shown the
                expected results as well.
                <!--l. 323--><p class="indent" >   To illustrate more about  the result let&#8217;s take the graph of an object&#8217;s tracker and detected
                confidence
                <!--l. 326--><p class="indent" >   <img 
                src="img/Selection_003.png" alt="PIC"  
                >
                <!--l. 328--><p class="indent" >   The improved confidence /build up confidence of object is equivalent to the
                confidence of the tracker .
                <!--l. 331--><p class="indent" >   From frame 0 to 10 the confidence of tracker is falling as the number
                of losses is increasing this is analogous to the situation where human first
                think that a object is &#8220;X&#8221; with confidence of almost 0.5 then next moment
                is he/she think that object is another object &#8220;Y&#8221; due to the unabilty to
                
                track the object movement in low lighting condition or because of other
                reason.
                <!--l. 338--><p class="indent" >   From frame 10 to 25 tracker confidence starts rising as hits is increasing this is
                analogus to the situation where a human starts to identify an object to be &#8220;X&#8221;
                continuously but with low confidence may be due to lighting condition or due to any
                other factors and after continuous gazing he is able to identify the object with almost
                100% of confidence.
                

                <!--l. 407--><p class="noindent" >
                     <dl class="list1"><dt class="list">
                     </dt><dd 
                class="list">
                     <!--l. 407--><p class="noindent" ><span 
                class="ectt-1000">Task</span><span 
                class="ectt-1000">&#x00A0;has</span><span 
                class="ectt-1000">&#x00A0;been</span><span 
                class="ectt-1000">&#x00A0;successfully</span><span 
                class="ectt-1000">&#x00A0;completed</span><span 
                class="ectt-1000">&#x00A0;by</span><span 
                class="ectt-1000">&#x00A0;implementing</span><span 
                class="ectt-1000">&#x00A0;the</span><span 
                class="ectt-1000">&#x00A0;</span>
                     <!--l. 410--><p class="noindent" ><span 
                class="ectt-1000">proposed</span><span 
                class="ectt-1000">&#x00A0;formula</span><span 
                class="ectt-1000">&#x00A0;in</span><span 
                class="ectt-1000">&#x00A0;different</span><span 
                class="ectt-1000">&#x00A0;situations</span><span 
                class="ectt-1000">&#x00A0;and</span><span 
                class="ectt-1000">&#x00A0;getting</span><span 
                class="ectt-1000">&#x00A0;the</span><span 
                class="ectt-1000">&#x00A0;desired</span><span 
                class="ectt-1000">&#x00A0;result.</span></dd></dl>
                

                <!--l. 446--><p class="indent" >   <span 
                class="tcrm-1000">&#8226; </span>software prerequisites
                     <div class="quote">
                     <!--l. 448--><p class="noindent" ><span 
                class="tcrm-1000">&#8226; </span>Python 3
                     <!--l. 450--><p class="noindent" ><span 
                class="tcrm-1000">&#8226; </span>Open CV
                
                     <!--l. 452--><p class="noindent" >For GPU compatibility
                     <!--l. 454--><p class="noindent" ><span 
                class="tcrm-1000">&#8226; </span>CUDA and CUDNN
                     <!--l. 456--><p class="noindent" ><span 
                class="tcrm-1000">&#8226; </span>darknet</div>
                <!--l. 459--><p class="noindent" >
                   <h4 class="likesubsectionHead"><a 
                 id="x1-7000"></a>SCOPE OF FUTURE WORK</h4>
                     <ul class="itemize1">
                     <li class="itemize">The choice of detection and tracking algorithim</li></ul>
                <!--l. 463--><p class="noindent" >A better tracking algorithim can be adopted to improve accuracy of the proposed
                algorithm. However, this is subjected to the trade-off of time complexity/frame rate
                of the algorithm.
                <!--l. 467--><p class="indent" >   A better detection algorithim can be used to detect to the object in low lightling
                condition.
                <!--l. 470--><p class="indent" >   An exhausive trining of the detection algorithm is required for currectly detecting
                objects in an aerial image.
                <!--l. 473--><p class="noindent" >
                   <h4 class="likesubsectionHead"><a 
                 id="x1-8000"></a></h4>            
        </div>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section class="blog-post-area">
            <div class="container">

                <div class="row2">
                    <div class="column2">
                      <h2>Project In Charge Professor </h2>
                      <p><li><a href="#">Dr Mrinal Sen</a></li>
                        </p>
                        <h2>Team member</h2>
                        
                        <p><li><a href="../index.html">Pr@jwal Th@kur</a></li>
                          </p>
                    </div>
                    <div class="column2">
                      <h2>My Contribution</h2>
                      <p>
                        <li>Helping in Developent of Algorithm with Dr Mrinal Sen </li>
                        <li>studied Kalman filter, Deep sort based tracking Algorithms and modified them as per our needs  </li>
                        <li>Modified the Script to as per the requirements of DRDO and run it on NVIDIA-JETSON-TX2 for further research in real time computation by drones </li>
                      </p>
                    </div>
                </div> 
    
                <div class="row2">
                    <div class="column2">
                      <h2>Work Progress</h2>
                      <p>Final demonstration  has been given to DRDO, preparing confrence paper
                        <h4><span class="date">3 January 2020</span></h4></p>
                    </div>
                   <!-- <div class="column2">
                      <h2>Components_required</h2>
                      <p>
                        <li>BEAGLE-3P-BBONE-AI:BeagleBone AI AM5729 , Microprocessor-AM57X SITARA</li>
                        <li>QUANTUM USB Sound Card, LOGITECH 5 MEXAPIXEL WEB CAMERA</li>
                      </p>
                    </div>-->
                </div>
                
            </div>
            
           <!-- <div class="pegination">
                
                <ul>
                    <li><i class="fa fa-angle-left" aria-hidden="true"></i></li>
                    <li class="active">1</li>
                    <li>2</li>
                    <li>3</li>
                    <li><i class="fa fa-angle-right" aria-hidden="true"></i></li>
                </ul>


                <div class="nav-links">
                    <span class="page-numbers current">1</span>
                    <a class="page-numbers" href="#">2</a>
                    <a class="page-numbers" href="#">3</a>
                    <a class="page-numbers" href="#">4</a>
                    <a class="page-numbers" href="#">5</a>
                    <a class="page-numbers" href="#"><i class="fa fa-angle-right" aria-hidden="true"></i></a>
                </div>
            </div>
        </section> -->
        <footer class="footer">
            <div class="container">
                <div class="row">
                    <div class="col-md-12">
                        <div class="footer-bg">
                            <div class="row">
                                <div class="col-md-9">
                                    <div class="footer-menu">
                                        <!--<ul>
                                            <li class="active"><a href="#">Home</a></li>
                                            <li><a href="#">lifestyle</a></li>
                                            <li><a href="#">Food</a></li>
                                            <li><a href="#">Nature</a></li>
                                            <li><a href="#">photography</a></li>
                                        </ul>-->
                                    </div>
                                </div>
                                <div class="col-md-3">
                                    <div class="footer-icon">
                                        <p><a href="#"><i class="fa fa-facebook" aria-hidden="true"></i></a><a href="#"><i class="fa fa-twitter" aria-hidden="true"></i></a><a href="#"><i class="fa fa-linkedin" aria-hidden="true"></i></a><a href="#"><i class="fa fa-dribbble" aria-hidden="true"></i></a></p>
                                    </div>
                                </div>
                            </div> .
                        </div>
                    </div>
                </div>
            </div>
        </footer>
    </div> 
    <script src="js/jquery-3.1.1.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/owl.carousel.min.js"></script>
    <script src="js/active.js"></script>
</body>

</html>